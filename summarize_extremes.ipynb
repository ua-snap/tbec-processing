{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c4131a3-d174-41ac-a343-e95ea5e04d3c",
   "metadata": {},
   "source": [
    "# Summarize extreme datasets\n",
    "\n",
    "This notebook is for creating summaries of the extreme variables derived from the CORDEX data. This will involve spreadsheets containing summarized data as well as some simple summary graphics.\n",
    "\n",
    "### Eras\n",
    "\n",
    "The eras of interest for summarizing these extremes will be:\n",
    "\n",
    "* 2011-2040\n",
    "* 2041-2070\n",
    "* 2071-2100\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dafbd28b-415e-40d2-83ee-517764822f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# write to the final_products/auxiliary_content directory, as the outputs from here will be used for reporting\n",
    "out_dir = Path(os.getenv(\"OUTPUT_DIR\") or \"/workspace/Shared/Tech_Projects/TBEC_CMIP5_Processing/final_products/\")\n",
    "extremes_fp = out_dir.joinpath(\"annual_extremes.nc\")\n",
    "extr_summary_fp = out_dir.joinpath(\"extremes_extractions.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfad659-3cfc-42e1-ae57-316ad5853a0a",
   "metadata": {},
   "source": [
    "Open connection to the extremes dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11f6f51d-d5e7-4100-8ed9-3832fc6696f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "\n",
    "ds = xr.open_dataset(extremes_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355f538f-0666-493b-ad78-10b48ff17ecc",
   "metadata": {},
   "source": [
    "## Excel spreadsheet\n",
    "\n",
    "Create an excel spreadsheet of tidy tables of summarized extreme variables, where each worksheet is one of the study locations. Each tidy table will have the following headers:\n",
    "\n",
    "* `model`\n",
    "* `scenario`\n",
    "* `era` (time period)\n",
    "* `aggr` (aggregate variable)\n",
    "* `variable`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60334d45-c801-4c7d-aef4-d669e38b3a89",
   "metadata": {},
   "source": [
    "Create some iterables for extracting the various summaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a3eebca-8c3a-4d2a-9bd1-0d7cf56c4b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eras = [\n",
    "    # \"1981-2010\",\n",
    "    \"2011-2040\",\n",
    "    \"2041-2070\",\n",
    "    \"2071-2100\",\n",
    "]\n",
    "# only need to iterate over these two scenarios, since \n",
    "#  \"historical\" era actually contains 5 years from \n",
    "#  either of the future scenarios\n",
    "scenarios = [\"rcp45\", \"rcp85\"]\n",
    "\n",
    "# summary variables\n",
    "# aggr_var_lu = {\n",
    "#     \"min\": np.min,\n",
    "#     \"mean\": np.mean,\n",
    "#     \"max\": np.max,\n",
    "# }\n",
    "\n",
    "varnames = [\"rx1say\", \"hsd\", \"hd\", \"cd\"]\n",
    "\n",
    "# dict of WGS84 coords for each of the locations\n",
    "locations = {\n",
    "    \"Kaktovik\": (70.1, -143.6),\n",
    "    \"Stevens Village\": (66.1, -149.1),\n",
    "    \"Igiugik Village\": (59.3, -155.9),\n",
    "    \"Levelock\": (59.1, -156.9),\n",
    "    # \"Nelson Lagoon\": (55.9, -161.2),\n",
    "    \"Eyak\": (60.5, -145.6),\n",
    "    \"Ketchikan\": (55.6, -136.6),\n",
    "    # \"Unalaska\": (53.9, -166.5),\n",
    "    \"Aleutians\": (57.838, -159.995),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a69c5e-4411-4d74-a5ee-0f21af74bebe",
   "metadata": {},
   "source": [
    "Create an excel dataset writer object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad6c8dbf-8e70-4316-a6e0-7c7e9fc896a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "writer = pd.ExcelWriter(extr_summary_fp, engine=\"xlsxwriter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428c0934-f1ff-49a3-b585-5056288a50b4",
   "metadata": {},
   "source": [
    "Iterate! Iterate! Loop over all possibilities and populate the excel sheet, inefficently but straightforwardly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "948682a2-97c2-4082-b1d1-da756dc30a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaktovik done\n",
      "Stevens Village done\n",
      "Igiugik Village done\n",
      "Levelock done\n",
      "Eyak done\n",
      "Ketchikan done\n",
      "Aleutians done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "dfs = []\n",
    "for location in locations:\n",
    "    lat, lon = locations[location]\n",
    "    \n",
    "    df_rows = []\n",
    "    \n",
    "    for era in eras:\n",
    "        start_year, end_year = era.split(\"-\")\n",
    "        for model in ds.model.values:\n",
    "            for scenario in scenarios:\n",
    "                for varname in varnames:\n",
    "                    da = ds[varname].sel(\n",
    "                        model=model,\n",
    "                        scenario=scenario,\n",
    "                        year=slice(int(start_year), int(end_year))\n",
    "                    ).sel(\n",
    "                        lat=lat,\n",
    "                        lon=lon,\n",
    "                        method=\"nearest\"\n",
    "                    )\n",
    "                    # for aggr_var in aggr_var_lu:\n",
    "\n",
    "                    df_rows.append({\n",
    "                        \"model\": model,\n",
    "                        \"scenario\": scenario,\n",
    "                        \"era\": era,\n",
    "                        \"varname\": varname,\n",
    "                        \"min\": np.nanmin(da.values).round(1),\n",
    "                        \"mean\": np.nanmean(da.values).round(1),\n",
    "                        \"max\": np.nanmax(da.values).round(1),\n",
    "                    })\n",
    "    \n",
    "    # create dataframe write dataframe to a sheet in the excel file   \n",
    "    df = pd.DataFrame(df_rows)\n",
    "    dfs.append(df)\n",
    "    df.to_excel(writer, sheet_name=location, index=False)\n",
    "    print(f\"{location} done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add18edf-4ef4-4e37-a44c-9aeea7c46b3e",
   "metadata": {},
   "source": [
    "Save the Excel spreadsheet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cc6ea1b-28ea-4923-92b8-596f3b74736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
