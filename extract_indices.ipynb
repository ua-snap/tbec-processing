{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c4131a3-d174-41ac-a343-e95ea5e04d3c",
   "metadata": {},
   "source": [
    "# Extract point locations\n",
    "\n",
    "This notebook is for extracting and summarizing the indices derived from the CORDEX data at specified point locations specified in `config.py`. We will store these data extractions in CSV files for ease of use, where each CSV contains a tidy table of extracted aggregations over three summary eras (listed below) for each location, as well as over all available decades for the CORDEX data.\n",
    "\n",
    "Each tidy table / CSV will have the following columns:\n",
    "\n",
    "* `model`\n",
    "* `scenario`\n",
    "* `era` / `decade`\n",
    "* `index` (index variable)\n",
    "* `min` (minimum value over era/decade)\n",
    "* `mean` (mean value over era/decade)\n",
    "* `max` (maximum value over era/decade)\n",
    "\n",
    "#### Summary eras\n",
    "\n",
    "The eras of interest for summarizing these extremes will be:\n",
    "\n",
    "* 2011-2040\n",
    "* 2041-2070\n",
    "* 2071-2100\n",
    "\n",
    "#### Summary decades\n",
    "\n",
    "We will also summarize the data over all available decades, from 1980-1989 to 2090-2099.\n",
    "\n",
    "#### Excel spreadsheet\n",
    "\n",
    "For ease of sharing these extractions with collaborators, this notebook will also create an excel spreadsheet (`.xlsx` format) from those tidy tables of summarized indices saved to `.csv` files, with worksheet being one of the study locations. We will just populate this excel file at the same time we create the `.csv` files.\n",
    "\n",
    "## Run the extraction\n",
    "\n",
    "Run the cell below first to set up paths and set up the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deec52ed-877e-4a1a-b708-6cf2f3c4aed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfad659-3cfc-42e1-ae57-316ad5853a0a",
   "metadata": {},
   "source": [
    "Open connection to the indices dataset, which will be used for both era and decadal sumamries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11f6f51d-d5e7-4100-8ed9-3832fc6696f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(indices_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355f538f-0666-493b-ad78-10b48ff17ecc",
   "metadata": {},
   "source": [
    "### Era summaries\n",
    "\n",
    "Extract and summarize the indices over the future eras. Define the eras to summarize over:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a3eebca-8c3a-4d2a-9bd1-0d7cf56c4b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eras = [\n",
    "    \"2011-2040\",\n",
    "    \"2041-2070\",\n",
    "    \"2071-2100\",\n",
    "]\n",
    "\n",
    "# list of the index variable names available from config\n",
    "index_list = [name for index_list in idx_varname_lu.values() for name in index_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a69c5e-4411-4d74-a5ee-0f21af74bebe",
   "metadata": {},
   "source": [
    "Create an excel dataset writer object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad6c8dbf-8e70-4316-a6e0-7c7e9fc896a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(idx_era_summary_fp, engine=\"openpyxl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428c0934-f1ff-49a3-b585-5056288a50b4",
   "metadata": {},
   "source": [
    "Iterate! Iterate! Loop over all possibilities and populate the excel sheet, inefficently but straightforwardly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "948682a2-97c2-4082-b1d1-da756dc30a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaktovik done\n",
      "Stevens Village done\n",
      "Igiugik Village done\n",
      "Levelock done\n",
      "Eyak done\n",
      "Ketchikan done\n",
      "Aleutians done\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for location in locations:\n",
    "    lat, lon = locations[location]\n",
    "    \n",
    "    df_rows = []\n",
    "    \n",
    "    for era in eras:\n",
    "        start_year, end_year = era.split(\"-\")\n",
    "        for model in ds.model.values:\n",
    "            for scenario in scenarios:\n",
    "                for index in index_list:\n",
    "                    da = ds[index].sel(\n",
    "                        model=model,\n",
    "                        scenario=scenario,\n",
    "                        year=slice(int(start_year), int(end_year))\n",
    "                    ).sel(\n",
    "                        lat=lat,\n",
    "                        lon=lon,\n",
    "                        method=\"nearest\"\n",
    "                    )\n",
    "                    # for aggr_var in aggr_var_lu:\n",
    "\n",
    "                    df_rows.append({\n",
    "                        \"model\": model,\n",
    "                        \"scenario\": scenario,\n",
    "                        \"era\": era,\n",
    "                        \"index\": index,\n",
    "                        \"min\": np.nanmin(da.values).round(1),\n",
    "                        \"mean\": np.nanmean(da.values).round(1),\n",
    "                        \"max\": np.nanmax(da.values).round(1),\n",
    "                    })\n",
    "    \n",
    "    # create dataframe write dataframe to a sheet in the excel file   \n",
    "    df = pd.DataFrame(df_rows)\n",
    "    dfs.append(df)\n",
    "    out_fp = idx_era_summary_dir.joinpath(f\"era_summaries_{location}.csv\")\n",
    "    df.to_csv(out_fp, index=False)\n",
    "    df.to_excel(writer, sheet_name=location, index=False)\n",
    "    print(f\"{location} done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add18edf-4ef4-4e37-a44c-9aeea7c46b3e",
   "metadata": {},
   "source": [
    "Save the Excel spreadsheet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cc6ea1b-28ea-4923-92b8-596f3b74736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fc811d-2732-4ca8-ba1c-116ee66cfeb5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Decdal summaries\n",
    "\n",
    "Now do the same as above, but for the decades. Define the decades:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62581b24-c7b4-4925-908a-45cee2dc102d",
   "metadata": {},
   "outputs": [],
   "source": [
    "decades = [f\"{year}-{year + 9}\" for year in np.arange(1980, 2091, 10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2f1215-bb0c-44ac-b58c-7eb914c5666e",
   "metadata": {},
   "source": [
    "Open Excel writer object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b486b085-5ca1-42f4-bdd7-e199270bdddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "decade_writer = pd.ExcelWriter(idx_decade_summary_fp, engine=\"openpyxl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca3e0c0-f343-47dd-b2dd-51ca65fab363",
   "metadata": {},
   "source": [
    "Define functions for summarizing the data from the point-extracted values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d75e3653-d995-4852-ae4c-f33b18bffac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_data(ds, varname, model, scenario, year_sl, lat, lon):\n",
    "    \"\"\"Subset an xarray dataset\"\"\"\n",
    "    da = ds[varname].sel(\n",
    "        model=model,\n",
    "        scenario=scenario,\n",
    "        year=year_sl\n",
    "    ).sel(\n",
    "        lat=lat,\n",
    "        lon=lon,\n",
    "        method=\"nearest\"\n",
    "    )\n",
    "    return da\n",
    "    \n",
    "def summarize_to_row(da, model, scenario, decade, index):\n",
    "    \"\"\"Summarize a data array and return a dict in format for\n",
    "    appending as pandas dataframe row to summary table\n",
    "    \"\"\"\n",
    "    row_di = {\n",
    "        \"model\": model,\n",
    "        \"scenario\": scenario,\n",
    "        \"decade\": decade,\n",
    "        \"index\": index,\n",
    "        \"min\": np.nanmin(da.values).round(1),\n",
    "        \"mean\": np.nanmean(da.values).round(1),\n",
    "        \"max\": np.nanmax(da.values).round(1),\n",
    "    }\n",
    "    return row_di"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c035cde6-2598-4a5f-8051-4b784c89de28",
   "metadata": {},
   "source": [
    "We have a bit of a wrinkle with the historical decades here being separate from the future scenarios: two decades are completely \"historical\" scenario, and the 2000-2009 decade overlaps the boundary between historical and future. For the historical decades, we will just save those separately as we will for the future decades. For the special decade though, we will summarize for the future scenarios separately, even though both will be based on data that have about 5 years of overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7ee45fd-5069-4cfc-9e3a-a7cdb79753b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaktovik done\n",
      "Stevens Village done\n",
      "Igiugik Village done\n",
      "Levelock done\n",
      "Eyak done\n",
      "Ketchikan done\n",
      "Aleutians done\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for location in locations:\n",
    "    lat, lon = locations[location]\n",
    "    \n",
    "    df_rows = []\n",
    "    \n",
    "    for decade in decades:\n",
    "        start_year, end_year = decade.split(\"-\")\n",
    "        year_sl = slice(int(start_year), int(end_year))\n",
    "        for index in index_list:\n",
    "            if decade in [\"1980-1989\", \"1990-1999\"]:\n",
    "                # this will be the historical scenario\n",
    "                scenario = \"hist\"\n",
    "                for model in ds.model.values:\n",
    "                    da = subset_data(ds, index, model, scenario, year_sl, lat, lon)\n",
    "                    df_rows.append(summarize_to_row(da, model, scenario, decade, index))\n",
    "\n",
    "            elif decade == \"2000-2009\":\n",
    "                # mixed decade, do both and concatenate data arrays\n",
    "                hist_sl = slice(2000, 2005)\n",
    "                future_sl = slice(2006, 2009)\n",
    "                for model in ds.model.values:\n",
    "                    for scenario in scenarios:\n",
    "                        hist_da = subset_data(ds, index, model, \"hist\", year_sl, lat, lon)\n",
    "                        future_da = subset_data(ds, index, model, scenario, year_sl, lat, lon)\n",
    "                        da = xr.concat([hist_da, future_da], dim=\"year\")\n",
    "                        df_rows.append(summarize_to_row(da, model, scenario, decade, index))\n",
    "\n",
    "            else:\n",
    "                # future scenarios\n",
    "                for model in ds.model.values:\n",
    "                    for scenario in scenarios:\n",
    "                        da = subset_data(ds, index, model, scenario, year_sl, lat, lon)\n",
    "                        df_rows.append(summarize_to_row(da, model, scenario, decade, index))\n",
    "\n",
    "    # create dataframe write dataframe to a sheet in the excel file   \n",
    "    df = pd.DataFrame(df_rows)\n",
    "    dfs.append(df)\n",
    "    out_fp = idx_decade_summary_dir.joinpath(f\"decade_summaries_{location}.csv\")\n",
    "    df.to_csv(out_fp, index=False)\n",
    "    df.to_excel(decade_writer, sheet_name=location, index=False)\n",
    "    print(f\"{location} done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111131a2-022f-4683-81b0-8bdbdf065a78",
   "metadata": {},
   "source": [
    "Save and close connection to `ds`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73b251e6-2aee-4354-9ea8-800bc3923b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "decade_writer.save()\n",
    "ds.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a4f4b9-fca6-4c0f-9fe0-783245ac6bdb",
   "metadata": {},
   "source": [
    "##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
