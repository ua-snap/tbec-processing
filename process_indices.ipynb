{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "988f67bc-1803-46f1-8c97-eb51c850a0c7",
   "metadata": {},
   "source": [
    "# Process weather indices dataset\n",
    "\n",
    "This notebook is used to derive a dataset of different indices / extreme events using the bias-corrected CORDEX data provided to Two Bears Environmental Consulting (via KR at SNAP) by Stantec, Inc.\n",
    "\n",
    "This dataset will consist of four indices (to start), derived at the annual scale for all available models and scenarios on the same grid as the original bias-corrected CORDEX data.\n",
    "\n",
    "This dataset will be stored in a netCDF file consisting of a dataset for each variable with the following dimensions:\n",
    "\n",
    "* model\n",
    "* scenario\n",
    "* year\n",
    "* Y\n",
    "* X\n",
    "\n",
    "## Indices\n",
    "\n",
    "The following indices are to be derived, at the annual scale:\n",
    "\n",
    "* `hd`:  “Hot day” threshold -- the highest observed daily $T_{max}$ such that there are 5 other observations equal to or greater than this value.\n",
    "* `cd`: “Cold day” threshold -- the lowest observed daily $T_{min}$ such that there are 5 other observations equal to or less than this value.\n",
    "* `rx1day`: Maximum 1-day precipitation\n",
    "* `hsd`: Heavy Snow Days –- the mean of the snow totals for the 5 snowiest days\n",
    "* `su`: Summer Days –- Annual number of days with Tmax above 25 C\n",
    "* `dw`: Deep Winter days –- Annual number of days with Tmin below -30 C\n",
    "* `wsdi`: Warm Spell Duration Index -- Annual count of occurrences of at least 5 consecutive days with daily mean T above 90 th percentile of historical values for the date\n",
    "* `cdsi`: Cold Spell Duration Index -- Same as WDSI, but for daily mean T below 10 th percentile\n",
    "* `rx5day`: Maximum 5-day precipitation\n",
    "* `r10mm`: Number of heavy precip days –- Annual count of days with precip > 10 mm\n",
    "* `cwd`: Consecutive wet days –- Yearly number of the most consecutive days with precip > 1 mm\n",
    "* `cdd`: Consecutive dry days –- Same as CED, but for days with precip < 1 mm\n",
    "* `wndd`: Windy Days – Yearly number of days with mean wind speed > 10 m/sec\n",
    "\n",
    "## Models\n",
    "\n",
    "The CORDEX data are created by combining a regional climate model with a global circulation model, and there are a couple different types of each represented in this dataset. The combinations are nowhere near exhaustive though, so for our purposes, it should be sufficient to just treat each unique combination as its own \"model\", of which there are 11:\n",
    "\n",
    "* CCCma-CanESM2 x CCCma-CanRCM4\n",
    "* CCCma-CanESM2 x SMHI-RCA4\n",
    "* CCCma-CanESM2 x UQAM-CRCM5\n",
    "* ICHEC-EC-EARTH x DMI-HIRHAM5\n",
    "* ICHEC-EC-EARTH x SMHI-RCA4\n",
    "* ICHEC-EC-EARTH x SMHI-RCA4-SN\n",
    "* MPI-M-MPI-ESM-LR x MGO-RRCM\n",
    "* MPI-M-MPI-ESM-LR x SMHI-RCA4\n",
    "* MPI-M-MPI-ESM-LR x SMHI-RCA4-SN\n",
    "* MPI-M-MPI-ESM-MR x UQAM-CRCM5\n",
    "* NCC-NorESM1-M x SMHI-RCA4\n",
    "\n",
    "## Processing\n",
    "\n",
    "Here we now derive this dataset. The strategy will be to iterate over the datasets and read / summarize into summary `xarray.DataArray` objects with matching dimensions, and then combined into one `xarray.Dataset` to then be saved as a netCDF. \n",
    "\n",
    "Run the cell below to import the config file which sets paths to directories, makes common imports, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c690b43d-fd4a-41b4-85e3-9a19aabe292d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import xarray as xr\n",
    "# project\n",
    "from config import *\n",
    "import indices\n",
    "# ignore all-nan slice warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', r'All-NaN (slice|axis) encountered')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63e0457-0db7-44cd-90b3-9af1d905ec46",
   "metadata": {},
   "source": [
    "Create a list of arguments for filenames and requested summaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f7f792c-c633-400f-86c2-1eb99a25af6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this chunk is an artifact of multiprocessing-based optimization attempts\n",
    "#  but it still serves nicely for utilizing a tqdm progress bar in serial processing\n",
    "args = []\n",
    "\n",
    "for scenario in scenarios:\n",
    "    for varname in varnames:\n",
    "        for model in models:\n",
    "            fp = cordex_dir.joinpath(scenario, varname, temp_fn.format(scenario, varname, model))\n",
    "            \n",
    "            # aggregate variable names for this particular file\n",
    "            idx_varnames = idx_varname_lu[varname]\n",
    "            \n",
    "            # not all combinations of model, scenario, and model variable actually exist\n",
    "            if fp.exists():\n",
    "                args.append((fp, idx_varnames, varname, scenario, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7566a4f-964f-4e24-9f45-240e0debc269",
   "metadata": {},
   "source": [
    "We will use functions from the `indices.py` script to derive the indices. Define a wrapper function for the `compute_index` function that will open the connection to a dataset (modeled climate variable) and compute all requested indices for that particular file.\n",
    "\n",
    "Note - currently, there is only one index computed per variable, but this approach was chosen to facilitate addition of multiple indices per variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68536fb0-4ec4-43c0-84e9-12bee6351daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_compute_index(args):\n",
    "    \"\"\"Read in data and compute all requested indices for a particular model variable, scenario, and model.\n",
    "    \n",
    "    Args:\n",
    "        fp (path-like): path to the file for the variable required for creating the index variables in indices\n",
    "        index_list (list): indices to derive using data in provided filepath\n",
    "        varname (str): model variable being used for indices\n",
    "        scenario (str): scenario being run\n",
    "        model (str): model being run\n",
    "        \n",
    "    Returns:\n",
    "        summary_das (tuple): tuple of the form (da, index, scenario, model), where da is a DataArray with dimensions of year (summary year), latitude (lat) and longitude (lon)\n",
    "    \"\"\"\n",
    "    fp, index_list, varname, scenario, model = args\n",
    "    # passing in model, scenario, agregate variable name\n",
    "    #  so this information can be handed back after\n",
    "    #  pool-ing to then construct new Dataset\n",
    "    \n",
    "    with xr.open_dataset(fp) as ds:\n",
    "        out = [indices.compute_index(ds[varname], index, model, scenario) for index in index_list]\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3125d065-6e07-4ab7-ae83-c2911f5fd184",
   "metadata": {},
   "source": [
    "Iterate over the arguments created for each index and run. Looks like this seems to be taking ~6 minutes on Atlas using 32 cores if the CORDEX data is available on scratch space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a71d630-adbd-4f61-ae97-324c86231358",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████████████████████████████████████████████████████████████████████████████████▎                             | 98/133 [06:20<02:16,  3.89s/it]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 6.72 GiB for an array with shape (153, 68, 365, 95, 5) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/UA/kmredilla/miniconda3/envs/tbec-processing/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/tmp/ipykernel_3404/1478809866.py\", line 20, in run_compute_index\n    out = [indices.compute_index(ds[varname], index, model, scenario) for index in index_list]\n  File \"/tmp/ipykernel_3404/1478809866.py\", line 20, in <listcomp>\n    out = [indices.compute_index(ds[varname], index, model, scenario) for index in index_list]\n  File \"/workspace/UA/kmredilla/tbec-processing/indices.py\", line 235, in compute_index\n    globals()[index](da)\n  File \"/workspace/UA/kmredilla/tbec-processing/indices.py\", line 166, in csdi\n    tasmin_per = percentile_doy(tasmin, per=10).sel(percentiles=10)\n  File \"<boltons.funcutils.FunctionBuilder-0>\", line 2, in percentile_doy\n  File \"/home/UA/kmredilla/miniconda3/envs/tbec-processing/lib/python3.9/site-packages/xclim/core/formatting.py\", line 397, in _call_and_add_history\n    outs = func(*args, **kwargs)\n  File \"/home/UA/kmredilla/miniconda3/envs/tbec-processing/lib/python3.9/site-packages/xclim/core/calendar.py\", line 516, in percentile_doy\n    rrr = rr.assign_coords(time=ind).unstack(\"time\").stack(stack_dim=(\"year\", \"window\"))\n  File \"/home/UA/kmredilla/miniconda3/envs/tbec-processing/lib/python3.9/site-packages/xarray/core/dataarray.py\", line 2332, in stack\n    ds = self._to_temp_dataset().stack(\n  File \"/home/UA/kmredilla/miniconda3/envs/tbec-processing/lib/python3.9/site-packages/xarray/core/dataset.py\", line 4351, in stack\n    result = result._stack_once(dims, new_dim, index_cls, create_index)\n  File \"/home/UA/kmredilla/miniconda3/envs/tbec-processing/lib/python3.9/site-packages/xarray/core/dataset.py\", line 4267, in _stack_once\n    stacked_var = exp_var.stack(**{new_dim: dims})\n  File \"/home/UA/kmredilla/miniconda3/envs/tbec-processing/lib/python3.9/site-packages/xarray/core/variable.py\", line 1626, in stack\n    result = result._stack_once(dims, new_dim)\n  File \"/home/UA/kmredilla/miniconda3/envs/tbec-processing/lib/python3.9/site-packages/xarray/core/variable.py\", line 1592, in _stack_once\n    new_data = reordered.data.reshape(new_shape)\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 6.72 GiB for an array with shape (153, 68, 365, 95, 5) and data type float32\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# trying with less than max number of cpus on Atlas nodes to help with memory allocation errors\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Pool(\u001b[38;5;241m25\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m summary_da \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(\n\u001b[1;32m      6\u001b[0m         pool\u001b[38;5;241m.\u001b[39mimap_unordered(run_compute_index, args), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(args)\n\u001b[1;32m      7\u001b[0m     ):\n\u001b[1;32m      8\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(summary_da)\n",
      "File \u001b[0;32m~/miniconda3/envs/tbec-processing/lib/python3.9/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tbec-processing/lib/python3.9/multiprocessing/pool.py:870\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[0;32m--> 870\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "File \u001b[0;32m~/miniconda3/envs/tbec-processing/lib/python3.9/multiprocessing/pool.py:125\u001b[0m, in \u001b[0;36mworker\u001b[0;34m()\u001b[0m\n\u001b[1;32m    123\u001b[0m job, i, func, args, kwds \u001b[38;5;241m=\u001b[39m task\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 125\u001b[0m     result \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;01mTrue\u001b[39;00m, func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wrap_exception \u001b[38;5;129;01mand\u001b[39;00m func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _helper_reraises_exception:\n",
      "Cell \u001b[0;32mIn [3], line 20\u001b[0m, in \u001b[0;36mrun_compute_index\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# passing in model, scenario, agregate variable name\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#  so this information can be handed back after\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#  pool-ing to then construct new Dataset\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m xr\u001b[38;5;241m.\u001b[39mopen_dataset(fp) \u001b[38;5;28;01mas\u001b[39;00m ds:\n\u001b[0;32m---> 20\u001b[0m     out \u001b[38;5;241m=\u001b[39m [indices\u001b[38;5;241m.\u001b[39mcompute_index(ds[varname], index, model, scenario) \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m index_list]\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "Cell \u001b[0;32mIn [3], line 20\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# passing in model, scenario, agregate variable name\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#  so this information can be handed back after\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#  pool-ing to then construct new Dataset\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m xr\u001b[38;5;241m.\u001b[39mopen_dataset(fp) \u001b[38;5;28;01mas\u001b[39;00m ds:\n\u001b[0;32m---> 20\u001b[0m     out \u001b[38;5;241m=\u001b[39m [indices\u001b[38;5;241m.\u001b[39mcompute_index(ds[varname], index, model, scenario) \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m index_list]\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/workspace/UA/kmredilla/tbec-processing/indices.py:235\u001b[0m, in \u001b[0;36mcompute_index\u001b[0;34m()\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_index\u001b[39m(da, index, model, scenario):\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;124;03m\"\"\"Summarize a DataArray according to a specified index / aggregation function\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;124;03m        A new data array with dimensions year, latitude, longitude, in that order containing the summarized information\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    234\u001b[0m     new_da \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 235\u001b[0m         \u001b[38;5;28mglobals\u001b[39m()[index](da)\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;241m.\u001b[39mreset_coords([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheight\u001b[39m\u001b[38;5;124m\"\u001b[39m], drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    238\u001b[0m     )\n\u001b[1;32m    239\u001b[0m     new_da\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m index\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# add model and scenario coordinate dimensions to the data array\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/UA/kmredilla/tbec-processing/indices.py:166\u001b[0m, in \u001b[0;36mcsdi\u001b[0;34m()\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcsdi\u001b[39m(tasmin):\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;124;03m\"\"\"'Cold spell duration index' - Annual count of occurrences of at least 5 consecutive days with daily min T below 10th percentile of historical values for the date\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m        Cold spell duration index for each year\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m     tasmin_per \u001b[38;5;241m=\u001b[39m percentile_doy(tasmin, per\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39msel(percentiles\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xci\u001b[38;5;241m.\u001b[39mcold_spell_duration_index(tasmin, tasmin_per, window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m, freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m<boltons.funcutils.FunctionBuilder-0>:2\u001b[0m, in \u001b[0;36mpercentile_doy\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/tbec-processing/lib/python3.9/site-packages/xclim/core/formatting.py:397\u001b[0m, in \u001b[0;36m_call_and_add_history\u001b[0;34m()\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_and_add_history\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;124;03m\"\"\"Call the function and then generate and add the history attr.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 397\u001b[0m     outs \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outs, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    400\u001b[0m         out \u001b[38;5;241m=\u001b[39m outs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/tbec-processing/lib/python3.9/site-packages/xclim/core/calendar.py:516\u001b[0m, in \u001b[0;36mpercentile_doy\u001b[0;34m()\u001b[0m\n\u001b[1;32m    510\u001b[0m rr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mrolling(min_periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, center\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, time\u001b[38;5;241m=\u001b[39mwindow)\u001b[38;5;241m.\u001b[39mconstruct(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwindow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    512\u001b[0m ind \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mMultiIndex\u001b[38;5;241m.\u001b[39mfrom_arrays(\n\u001b[1;32m    513\u001b[0m     (rr\u001b[38;5;241m.\u001b[39mtime\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39myear\u001b[38;5;241m.\u001b[39mvalues, rr\u001b[38;5;241m.\u001b[39mtime\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mdayofyear\u001b[38;5;241m.\u001b[39mvalues),\n\u001b[1;32m    514\u001b[0m     names\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdayofyear\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    515\u001b[0m )\n\u001b[0;32m--> 516\u001b[0m rrr \u001b[38;5;241m=\u001b[39m rr\u001b[38;5;241m.\u001b[39massign_coords(time\u001b[38;5;241m=\u001b[39mind)\u001b[38;5;241m.\u001b[39munstack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstack(stack_dim\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwindow\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rrr\u001b[38;5;241m.\u001b[39mchunks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(rrr\u001b[38;5;241m.\u001b[39mchunks[rrr\u001b[38;5;241m.\u001b[39mget_axis_num(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m)]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    519\u001b[0m     \u001b[38;5;66;03m# Preserve chunk size\u001b[39;00m\n\u001b[1;32m    520\u001b[0m     time_chunks_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(arr\u001b[38;5;241m.\u001b[39mchunks[arr\u001b[38;5;241m.\u001b[39mget_axis_num(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m)])\n",
      "File \u001b[0;32m~/miniconda3/envs/tbec-processing/lib/python3.9/site-packages/xarray/core/dataarray.py:2332\u001b[0m, in \u001b[0;36mstack\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2267\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstack\u001b[39m(\n\u001b[1;32m   2268\u001b[0m     \u001b[38;5;28mself\u001b[39m: T_DataArray,\n\u001b[1;32m   2269\u001b[0m     dimensions: Mapping[Any, Sequence[Hashable]] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2272\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdimensions_kwargs: Sequence[Hashable],\n\u001b[1;32m   2273\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T_DataArray:\n\u001b[1;32m   2274\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2275\u001b[0m \u001b[38;5;124;03m    Stack any number of existing dimensions into a single new dimension.\u001b[39;00m\n\u001b[1;32m   2276\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2330\u001b[0m \u001b[38;5;124;03m    DataArray.unstack\u001b[39;00m\n\u001b[1;32m   2331\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2332\u001b[0m     ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_temp_dataset()\u001b[38;5;241m.\u001b[39mstack(\n\u001b[1;32m   2333\u001b[0m         dimensions,\n\u001b[1;32m   2334\u001b[0m         create_index\u001b[38;5;241m=\u001b[39mcreate_index,\n\u001b[1;32m   2335\u001b[0m         index_cls\u001b[38;5;241m=\u001b[39mindex_cls,\n\u001b[1;32m   2336\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdimensions_kwargs,\n\u001b[1;32m   2337\u001b[0m     )\n\u001b[1;32m   2338\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_from_temp_dataset(ds)\n",
      "File \u001b[0;32m~/miniconda3/envs/tbec-processing/lib/python3.9/site-packages/xarray/core/dataset.py:4351\u001b[0m, in \u001b[0;36mstack\u001b[0;34m()\u001b[0m\n\u001b[1;32m   4349\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m   4350\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m new_dim, dims \u001b[38;5;129;01min\u001b[39;00m dimensions\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m-> 4351\u001b[0m     result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m_stack_once(dims, new_dim, index_cls, create_index)\n\u001b[1;32m   4352\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/tbec-processing/lib/python3.9/site-packages/xarray/core/dataset.py:4267\u001b[0m, in \u001b[0;36m_stack_once\u001b[0;34m()\u001b[0m\n\u001b[1;32m   4265\u001b[0m shape \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims[d] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m vdims]\n\u001b[1;32m   4266\u001b[0m exp_var \u001b[38;5;241m=\u001b[39m var\u001b[38;5;241m.\u001b[39mset_dims(vdims, shape)\n\u001b[0;32m-> 4267\u001b[0m stacked_var \u001b[38;5;241m=\u001b[39m exp_var\u001b[38;5;241m.\u001b[39mstack(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{new_dim: dims})\n\u001b[1;32m   4268\u001b[0m new_variables[name] \u001b[38;5;241m=\u001b[39m stacked_var\n\u001b[1;32m   4269\u001b[0m stacked_var_names\u001b[38;5;241m.\u001b[39mappend(name)\n",
      "File \u001b[0;32m~/miniconda3/envs/tbec-processing/lib/python3.9/site-packages/xarray/core/variable.py:1626\u001b[0m, in \u001b[0;36mstack\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1624\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m   1625\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m new_dim, dims \u001b[38;5;129;01min\u001b[39;00m dimensions\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m-> 1626\u001b[0m     result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m_stack_once(dims, new_dim)\n\u001b[1;32m   1627\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/tbec-processing/lib/python3.9/site-packages/xarray/core/variable.py:1592\u001b[0m, in \u001b[0;36m_stack_once\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1589\u001b[0m reordered \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m*\u001b[39mdim_order)\n\u001b[1;32m   1591\u001b[0m new_shape \u001b[38;5;241m=\u001b[39m reordered\u001b[38;5;241m.\u001b[39mshape[: \u001b[38;5;28mlen\u001b[39m(other_dims)] \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)\n\u001b[0;32m-> 1592\u001b[0m new_data \u001b[38;5;241m=\u001b[39m reordered\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mreshape(new_shape)\n\u001b[1;32m   1593\u001b[0m new_dims \u001b[38;5;241m=\u001b[39m reordered\u001b[38;5;241m.\u001b[39mdims[: \u001b[38;5;28mlen\u001b[39m(other_dims)] \u001b[38;5;241m+\u001b[39m (new_dim,)\n\u001b[1;32m   1595\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Variable(new_dims, new_data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attrs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encoding, fastpath\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 6.72 GiB for an array with shape (153, 68, 365, 95, 5) and data type float32"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "    \n",
    "# trying with less than max number of cpus on Atlas nodes to help with memory allocation errors\n",
    "with Pool(25) as pool:\n",
    "    for summary_da in tqdm.tqdm(\n",
    "        pool.imap_unordered(run_compute_index, args), total=len(args)\n",
    "    ):\n",
    "        results.append(summary_da)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006ccbe6-df9c-408d-82eb-4ba68a488c5e",
   "metadata": {},
   "source": [
    "Merge the `DataArray`s into one `DataSet` (this might take a couple minutes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d77ab45f-d397-4db8-902c-2bb8a6bfc95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.merge([da for da_list in results for da in da_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbd46b9-d909-4f35-988b-f8749317b2a0",
   "metadata": {},
   "source": [
    "Convert data to appropriate units as needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1346cd8-ab35-45c0-a384-76416efa20c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert precip indices to mm - conversion factor for precipitation flux to cm (from kg m-2 s-1) provided by John W is 8460.\n",
    "# ds[\"rx1day\"] = ds[\"rx1day\"] * 86400\n",
    "\n",
    "# # convert temperature to Celsius\n",
    "# ds[\"hd\"] = ds[\"hd\"] - 273.15\n",
    "# ds[\"cd\"] = ds[\"cd\"] - 273.15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0803a7-b51d-4906-adfa-3e9ace2fc67d",
   "metadata": {},
   "source": [
    "Set reasonable data types, converting `nan`s to -9999 as necessary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a54bb8c3-2ec5-4abb-9da1-4e753a1892fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_nan(da):\n",
    "    da.values[np.isnan(da.values)] = -9999\n",
    "    return da\n",
    "\n",
    "\n",
    "ds[\"hsd\"] = replace_nan(ds[\"hsd\"]).astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd89042-a0ac-4dc6-8e04-95d838a8832b",
   "metadata": {},
   "source": [
    "Round to reasonable precision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5acc0481-d9ad-4f5c-ac03-e99bde0450e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"hd\"] = np.round(ds[\"hd\"], 1)\n",
    "ds[\"cd\"] = np.round(ds[\"cd\"], 1)\n",
    "ds[\"rx1day\"] = np.round(ds[\"rx1day\"], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8812cfa2-41fa-40b7-b4e7-910938b10045",
   "metadata": {},
   "source": [
    "Add metadata as attributes of the `DataArray`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff4b3aa0-df2d-40f1-a097-bb1f1720e9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"hd\"].attrs = {\n",
    "    \"units\": \"C\",\n",
    "    \"comment\": \"'hot day': 6th hottest day of the year\",\n",
    "}\n",
    "ds[\"cd\"].attrs = {\n",
    "    \"units\": \"C\",\n",
    "    \"comment\": \"'cold day': 6th coldest day of the year\",\n",
    "}\n",
    "ds[\"rx1day\"].attrs = {\n",
    "    \"units\": \"mm\",\n",
    "    \"comment\": \"maximum precipitation for the year\",\n",
    "}\n",
    "ds[\"hsd\"].attrs = {\n",
    "    \"units\": \"day\",\n",
    "    \"comment\": \"number of days exceeding 10cm snowfall\",\n",
    "    \"_FillValue\": -9999,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b22f09-a2f6-46b1-9d7a-d015eda33705",
   "metadata": {},
   "source": [
    "Global metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35b4e673-33c6-450e-a61c-92d28b6905b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "ds.attrs = {\n",
    "    \"creation_date\": datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15973a9f-a908-49f7-b6cf-339daf903796",
   "metadata": {},
   "source": [
    "Write to disk (might take a couple of minutes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63202bbc-1bba-44fb-ad85-811ba01b3b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_netcdf(indices_fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
