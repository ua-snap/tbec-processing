{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c4131a3-d174-41ac-a343-e95ea5e04d3c",
   "metadata": {},
   "source": [
    "# Extract point locations\n",
    "\n",
    "This notebook is for extracting and summarizing the extreme variables derived from the CORDEX data at specified point locations. We will store these data extractions in an Excel file (`.xlsx`) where each spreadsheet contains a tidy table of extracted aggregations over three summary eras (listed below) for each location, as well as over all available decades\n",
    "\n",
    "#### Summary eras\n",
    "\n",
    "The eras of interest for summarizing these extremes will be:\n",
    "\n",
    "* 2011-2040\n",
    "* 2041-2070\n",
    "* 2071-2100\n",
    "\n",
    "#### Summary decades\n",
    "\n",
    "We will also summarize the data over all available decades, from 1980-1989 to 2090-2099.\n",
    "\n",
    "#### Excel spreadsheet\n",
    "\n",
    "This notebook will create an excel spreadsheet of tidy tables of summarized extreme variables, where each worksheet is one of the study locations. An excel spreadhseet is chosen instead of a CSV or other format because these may be of use to collaborators. Each tidy table will have the following headers:\n",
    "\n",
    "* `model`\n",
    "* `scenario`\n",
    "* `era` (time period)\n",
    "* `aggr` (aggregate variable)\n",
    "* `variable`\n",
    "\n",
    "## Run the extraction\n",
    "\n",
    "Run the cell below first to set up paths and set up the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "deec52ed-877e-4a1a-b708-6cf2f3c4aed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfad659-3cfc-42e1-ae57-316ad5853a0a",
   "metadata": {},
   "source": [
    "Read in the extremes dataset, which will be used for both era and decadal sumamries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11f6f51d-d5e7-4100-8ed9-3832fc6696f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.load_dataset(extremes_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355f538f-0666-493b-ad78-10b48ff17ecc",
   "metadata": {},
   "source": [
    "### Era summaries\n",
    "\n",
    "Extract the data and summarize over the eras. Define some iterables for extracting the various summaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a3eebca-8c3a-4d2a-9bd1-0d7cf56c4b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eras = [\n",
    "    # \"1981-2010\",\n",
    "    \"2011-2040\",\n",
    "    \"2041-2070\",\n",
    "    \"2071-2100\",\n",
    "]\n",
    "\n",
    "# only need to iterate over these two scenarios, since \n",
    "#  \"historical\" era actually contains 5 years from \n",
    "#  either of the future scenarios\n",
    "scenarios = [\"rcp45\", \"rcp85\"]\n",
    "\n",
    "# summary variables\n",
    "# aggr_var_lu = {\n",
    "#     \"min\": np.min,\n",
    "#     \"mean\": np.mean,\n",
    "#     \"max\": np.max,\n",
    "# }\n",
    "\n",
    "varnames = [\"rx1say\", \"hsd\", \"hd\", \"cd\"]\n",
    "\n",
    "# dict of WGS84 coords for each of the locations\n",
    "locations = {\n",
    "    \"Kaktovik\": (70.1, -143.6),\n",
    "    \"Stevens Village\": (66.1, -149.1),\n",
    "    \"Igiugik Village\": (59.3, -155.9),\n",
    "    \"Levelock\": (59.1, -156.9),\n",
    "    # \"Nelson Lagoon\": (55.9, -161.2),\n",
    "    \"Eyak\": (60.5, -145.6),\n",
    "    \"Ketchikan\": (55.6, -136.6),\n",
    "    # \"Unalaska\": (53.9, -166.5),\n",
    "    \"Aleutians\": (57.838, -159.995),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a69c5e-4411-4d74-a5ee-0f21af74bebe",
   "metadata": {},
   "source": [
    "Create an excel dataset writer object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad6c8dbf-8e70-4316-a6e0-7c7e9fc896a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(extr_era_summary_fp, engine=\"openpyxl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428c0934-f1ff-49a3-b585-5056288a50b4",
   "metadata": {},
   "source": [
    "Iterate! Iterate! Loop over all possibilities and populate the excel sheet, inefficently but straightforwardly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "948682a2-97c2-4082-b1d1-da756dc30a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaktovik done\n",
      "Stevens Village done\n",
      "Igiugik Village done\n",
      "Levelock done\n",
      "Eyak done\n",
      "Ketchikan done\n",
      "Aleutians done\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for location in locations:\n",
    "    lat, lon = locations[location]\n",
    "    \n",
    "    df_rows = []\n",
    "    \n",
    "    for era in eras:\n",
    "        start_year, end_year = era.split(\"-\")\n",
    "        for model in ds.model.values:\n",
    "            for scenario in scenarios:\n",
    "                for varname in varnames:\n",
    "                    da = ds[varname].sel(\n",
    "                        model=model,\n",
    "                        scenario=scenario,\n",
    "                        year=slice(int(start_year), int(end_year))\n",
    "                    ).sel(\n",
    "                        lat=lat,\n",
    "                        lon=lon,\n",
    "                        method=\"nearest\"\n",
    "                    )\n",
    "                    # for aggr_var in aggr_var_lu:\n",
    "\n",
    "                    df_rows.append({\n",
    "                        \"model\": model,\n",
    "                        \"scenario\": scenario,\n",
    "                        \"era\": era,\n",
    "                        \"varname\": varname,\n",
    "                        \"min\": np.nanmin(da.values).round(1),\n",
    "                        \"mean\": np.nanmean(da.values).round(1),\n",
    "                        \"max\": np.nanmax(da.values).round(1),\n",
    "                    })\n",
    "    \n",
    "    # create dataframe write dataframe to a sheet in the excel file   \n",
    "    df = pd.DataFrame(df_rows)\n",
    "    dfs.append(df)\n",
    "    df.to_excel(writer, sheet_name=location, index=False)\n",
    "    print(f\"{location} done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add18edf-4ef4-4e37-a44c-9aeea7c46b3e",
   "metadata": {},
   "source": [
    "Save the Excel spreadsheet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cc6ea1b-28ea-4923-92b8-596f3b74736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fc811d-2732-4ca8-ba1c-116ee66cfeb5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Decdal summaries\n",
    "\n",
    "Now do the same as above, but for the decades. Define the decades:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62581b24-c7b4-4925-908a-45cee2dc102d",
   "metadata": {},
   "outputs": [],
   "source": [
    "decades = [f\"{year}-{year + 9}\" for year in np.arange(1980, 2091, 10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2f1215-bb0c-44ac-b58c-7eb914c5666e",
   "metadata": {},
   "source": [
    "Open Excel writer object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b486b085-5ca1-42f4-bdd7-e199270bdddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "decade_writer = pd.ExcelWriter(extr_decade_summary_fp, engine=\"openpyxl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca3e0c0-f343-47dd-b2dd-51ca65fab363",
   "metadata": {},
   "source": [
    "Iterate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d75e3653-d995-4852-ae4c-f33b18bffac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_data(ds, varname, model, scenario, year_sl, lat, lon):\n",
    "    \"\"\"Subset an xarray dataset\"\"\"\n",
    "    da = ds[varname].sel(\n",
    "        model=model,\n",
    "        scenario=scenario,\n",
    "        year=year_sl\n",
    "    ).sel(\n",
    "        lat=lat,\n",
    "        lon=lon,\n",
    "        method=\"nearest\"\n",
    "    )\n",
    "    return da\n",
    "    \n",
    "def summarize_to_row(da, model, scenario, decade, varname):\n",
    "    \"\"\"Summarize a data array and return a dict in format for\n",
    "    appending as pandas dataframe row to summary table\n",
    "    \"\"\"\n",
    "    row_di = {\n",
    "        \"model\": model,\n",
    "        \"scenario\": scenario,\n",
    "        \"decade\": decade,\n",
    "        \"varname\": varname,\n",
    "        \"min\": np.nanmin(da.values).round(1),\n",
    "        \"mean\": np.nanmean(da.values).round(1),\n",
    "        \"max\": np.nanmax(da.values).round(1),\n",
    "    }\n",
    "    return row_di"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c035cde6-2598-4a5f-8051-4b784c89de28",
   "metadata": {},
   "source": [
    "We have a bit of a wrinkle with the historical decades here being separate from the future scenarios: two decades are completely \"historical\" scenario, and the 2000-2009 decade overlaps the boundary between historical and future. For the historical decades, we will just save those separately as we will for the future decades. For the special decade though, we will summarize for the future scenarios separately, even though both will be based on data that have about 5 years of overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b7ee45fd-5069-4cfc-9e3a-a7cdb79753b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaktovik done\n",
      "Stevens Village done\n",
      "Igiugik Village done\n",
      "Levelock done\n",
      "Eyak done\n",
      "Ketchikan done\n",
      "Aleutians done\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for location in locations:\n",
    "    lat, lon = locations[location]\n",
    "    \n",
    "    df_rows = []\n",
    "    \n",
    "    for decade in decades:\n",
    "        start_year, end_year = decade.split(\"-\")\n",
    "        year_sl = slice(int(start_year), int(end_year))\n",
    "        for varname in varnames:\n",
    "            if decade in [\"1980-1989\", \"1990-1999\"]:\n",
    "                # this will be the historical scenario\n",
    "                scenario = \"hist\"\n",
    "                for model in ds.model.values:\n",
    "                    da = subset_data(ds, varname, model, scenario, year_sl, lat, lon)\n",
    "                    df_rows.append(summarize_to_row(da, model, scenario, decade, varname))\n",
    "\n",
    "            elif decade == \"2000-2009\":\n",
    "                # mixed decade, do both and concatenate data arrays\n",
    "                hist_sl = slice(2000, 2005)\n",
    "                future_sl = slice(2006, 2009)\n",
    "                for model in ds.model.values:\n",
    "                    for scenario in scenarios:\n",
    "                        hist_da = subset_data(ds, varname, model, \"hist\", year_sl, lat, lon)\n",
    "                        future_da = subset_data(ds, varname, model, scenario, year_sl, lat, lon)\n",
    "                        da = xr.concat([hist_da, future_da], dim=\"year\")\n",
    "                        df_rows.append(summarize_to_row(da, model, scenario, decade, varname))\n",
    "\n",
    "            else:\n",
    "                # future scenarios\n",
    "                for model in ds.model.values:\n",
    "                    for scenario in scenarios:\n",
    "                        da = subset_data(ds, varname, model, scenario, year_sl, lat, lon)\n",
    "                        df_rows.append(summarize_to_row(da, model, scenario, decade, varname))\n",
    "\n",
    "    # create dataframe write dataframe to a sheet in the excel file   \n",
    "    df = pd.DataFrame(df_rows)\n",
    "    dfs.append(df)\n",
    "    df.to_excel(decade_writer, sheet_name=location, index=False)\n",
    "    \n",
    "    worksheet = decade_writer.sheets[location]\n",
    "    \n",
    "    worksheet.set_column(4, 6, None, format1) \n",
    "    print(f\"{location} done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "73b251e6-2aee-4354-9ea8-800bc3923b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "decade_writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a4f4b9-fca6-4c0f-9fe0-783245ac6bdb",
   "metadata": {},
   "source": [
    "##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
